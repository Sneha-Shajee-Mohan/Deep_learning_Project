{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "# Load pretrained BiSeNet and load the model weights separately)\n",
    "class BiSeNet(torch.nn.Module):\n",
    "    def __init__(self, n_classes=19):\n",
    "        super(BiSeNet, self).__init__()\n",
    "        from model import BiSeNet as BiSeNetModel  # from official face-parsing repo\n",
    "        self.model = BiSeNetModel(n_classes=n_classes)\n",
    "    \n",
    "    def load_weights(self, path):\n",
    "        self.model.load_state_dict(torch.load(\"/Users/sneha/Deep_Learn/project/project/final-project/79999_iter.pth\", weights_only=False, map_location='cpu'))\n",
    "        self.model.eval()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            out = self.model(x)[0]\n",
    "            parsing = out.squeeze(0).argmax(0).cpu().numpy()\n",
    "        return parsing\n",
    "\n",
    "def preprocess(image_path):\n",
    "    to_tensor = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet mean/std\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    img_resized = to_tensor(image).unsqueeze(0)\n",
    "    original = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "    return img_resized, original\n",
    "\n",
    "def extract_skin(image_rgb, parsing_mask):\n",
    "    # 1:for parsing skin depending on the BiSeNet label map\n",
    "    skin_mask = (parsing_mask == 1).astype(np.uint8)\n",
    "    skin = cv2.bitwise_and(image_rgb, image_rgb, mask=skin_mask)\n",
    "    return skin, skin_mask\n",
    "\n",
    "def mean_lab_skin(image_rgb, skin_mask):\n",
    "    image_lab = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2LAB)\n",
    "    skin_pixels = image_lab[skin_mask > 0]\n",
    "    return np.mean(skin_pixels, axis=0)\n",
    "\n",
    "def compute_stsi(image1_lab, image2_lab):\n",
    "    return np.linalg.norm(image1_lab - image2_lab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for processing images(extracting skin) and computing mean LAB & STSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean LAB (Image 1): [186.74291555 135.42496123 135.34491752]\n",
      "Mean LAB (Image 2): [186.19525702 137.77051708 140.14348383]\n",
      "STSI (Skin Tone Shift Index): 5.369152700648886\n"
     ]
    }
   ],
   "source": [
    "# Load model and weights\n",
    "net = BiSeNet(n_classes=19)\n",
    "net.load_weights(\"/Users/sneha/Deep_Learn/project/project/final-project/79999_iter.pth\") \n",
    "net.eval()\n",
    "\n",
    "# Process images\n",
    "img1_tensor, img1_original = preprocess(\"/Users/sneha/Deep_Learn/project/project/final-project/UTKFace/UTKFace/1_0_0_1.jpg\")\n",
    "img2_tensor, img2_original = preprocess(\"/Users/sneha/Deep_Learn/project/project/final-project/UTKFace/UTKFace-result/1_0_0_1.jpg\")\n",
    "\n",
    "# Get parsing maps\n",
    "parsing1 = net(img1_tensor)\n",
    "parsing2 = net(img2_tensor)\n",
    "\n",
    "def extract_skin(image_rgb, parsing_mask):\n",
    "    \"\"\"\n",
    "    image_rgb: OpenCV RGB image (H, W, 3)\n",
    "    parsing_mask: Face parsing mask output from BiSeNet (H, W)\n",
    "    \"\"\"\n",
    "    # Keep only pixels with label 1 (skin)\n",
    "    skin_mask = (parsing_mask == 1).astype(np.uint8)\n",
    "\n",
    "    # Ensure mask size matches image size\n",
    "    if skin_mask.shape != image_rgb.shape[:2]:\n",
    "        skin_mask = cv2.resize(skin_mask, (image_rgb.shape[1], image_rgb.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Make sure mask is uint8\n",
    "    skin_mask = skin_mask.astype(np.uint8)\n",
    "\n",
    "    # Apply mask to image\n",
    "    skin = cv2.bitwise_and(image_rgb, image_rgb, mask=skin_mask)\n",
    "    return skin, skin_mask\n",
    "\n",
    "\n",
    "\n",
    "# Extract skin regions\n",
    "skin1, mask1 = extract_skin(img1_original, parsing1)\n",
    "skin2, mask2 = extract_skin(img2_original, parsing2)\n",
    "\n",
    "# Compute mean LAB\n",
    "mean1 = mean_lab_skin(cv2.cvtColor(skin1, cv2.COLOR_BGR2RGB), mask1)\n",
    "mean2 = mean_lab_skin(cv2.cvtColor(skin2, cv2.COLOR_BGR2RGB), mask2)\n",
    "\n",
    "# Compute STSI\n",
    "stsi = compute_stsi(mean1, mean2)\n",
    "\n",
    "print(\"Mean LAB (Image 1):\", mean1)\n",
    "print(\"Mean LAB (Image 2):\", mean2)\n",
    "print(\"STSI (Skin Tone Shift Index):\", stsi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for computing STSI based on races(sample of 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24_0_0_5.jpg → STSI: 10.111\n",
      "24_0_0_7.jpg → STSI: 2.305\n",
      "24_0_0_18.jpg → STSI: 3.539\n",
      "24_0_0_19.jpg → STSI: 23.001\n",
      "24_0_0_6.jpg → STSI: 8.528\n",
      "24_0_0_2.jpg → STSI: 4.533\n",
      "24_0_0_21.jpg → STSI: 10.670\n",
      "24_0_0_20.jpg → STSI: 22.837\n",
      "24_0_0_3.jpg → STSI: 7.590\n",
      "24_0_0_1.jpg → STSI: 2.076\n",
      "1_0_0_15.jpg → STSI: 5.839\n",
      "1_0_0_14.jpg → STSI: 14.004\n",
      "1_0_0_16.jpg → STSI: 5.391\n",
      "1_0_0_17.jpg → STSI: 6.329\n",
      "1_0_0_13.jpg → STSI: 11.461\n",
      "1_0_0_9.jpg → STSI: 15.111\n",
      "1_0_0_8.jpg → STSI: 17.629\n",
      "1_0_0_12.jpg → STSI: 7.336\n",
      "1_0_0_10.jpg → STSI: 5.944\n",
      "1_0_0_11.jpg → STSI: 7.702\n",
      "1_0_0_20.jpg → STSI: 7.108\n",
      "1_0_0_6.jpg → STSI: 15.416\n",
      "1_0_0_7.jpg → STSI: 23.634\n",
      "1_0_0_5.jpg → STSI: 27.812\n",
      "1_0_0_4.jpg → STSI: 11.154\n",
      "1_0_0_1.jpg → STSI: 5.369\n",
      "1_0_0_19.jpg → STSI: 7.739\n",
      "1_0_0_3.jpg → STSI: 2.881\n",
      "1_0_0_2.jpg → STSI: 1.325\n",
      "1_0_0_18.jpg → STSI: 20.674\n",
      "24_0_0_12.jpg → STSI: 8.182\n",
      "24_0_0_13.jpg → STSI: 8.128\n",
      "24_0_0_11.jpg → STSI: 4.772\n",
      "24_0_0_10.jpg → STSI: 15.347\n",
      "24_0_0_14.jpg → STSI: 0.000\n",
      "24_0_0_15.jpg → STSI: 2.280\n",
      "24_0_0_8.jpg → STSI: 7.330\n",
      "24_0_0_17.jpg → STSI: 4.128\n",
      "24_0_0_16.jpg → STSI: 22.811\n",
      "24_0_0_9.jpg → STSI: 8.897\n",
      "\n",
      "✅ Mean STSI across 40 images: 9.923\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# -------- Helper Functions --------\n",
    "def extract_skin(image_rgb, parsing_mask):\n",
    "    skin_mask = (parsing_mask == 1).astype(np.uint8)\n",
    "    if skin_mask.shape != image_rgb.shape[:2]:\n",
    "        skin_mask = cv2.resize(skin_mask, (image_rgb.shape[1], image_rgb.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    skin_mask = skin_mask.astype(np.uint8)\n",
    "    skin = cv2.bitwise_and(image_rgb, image_rgb, mask=skin_mask)\n",
    "    return skin, skin_mask\n",
    "\n",
    "def mean_lab_skin(image_rgb, mask):\n",
    "    lab = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2LAB)\n",
    "    skin_pixels = lab[mask > 0]\n",
    "    return np.mean(skin_pixels, axis=0) if skin_pixels.size > 0 else np.array([0, 0, 0])\n",
    "\n",
    "def compute_stsi(mean1, mean2):\n",
    "    return np.linalg.norm(mean1 - mean2)\n",
    "\n",
    "def process_image_pair(original_path, recolored_path, net):\n",
    "    img1_tensor, img1_original = preprocess(original_path)\n",
    "    img2_tensor, img2_original = preprocess(recolored_path)\n",
    "\n",
    "    parsing1 = net(img1_tensor)\n",
    "    parsing2 = net(img2_tensor)\n",
    "\n",
    "    skin1, mask1 = extract_skin(img1_original, parsing1)\n",
    "    skin2, mask2 = extract_skin(img2_original, parsing2)\n",
    "\n",
    "    mean1 = mean_lab_skin(cv2.cvtColor(skin1, cv2.COLOR_BGR2RGB), mask1)\n",
    "    mean2 = mean_lab_skin(cv2.cvtColor(skin2, cv2.COLOR_BGR2RGB), mask2)\n",
    "\n",
    "    return compute_stsi(mean1, mean2), mean1, mean2\n",
    "\n",
    "# -------- Load Model --------\n",
    "net = BiSeNet(n_classes=19)\n",
    "net.load_weights(\"/Users/sneha/Deep_Learn/project/project/final-project/79999_iter.pth\")\n",
    "net.eval()\n",
    "\n",
    "# -------- Directory Setup --------\n",
    "original_dir = \"/Users/sneha/Deep_Learn/project/project/final-project/white-face\"\n",
    "recolored_dir = \"/Users/sneha/Deep_Learn/project/project/final-project/white-result\"\n",
    "\n",
    "filenames = [f for f in os.listdir(original_dir) if f.endswith(\".jpg\")][:40]\n",
    "\n",
    "stsi_values = []\n",
    "\n",
    "for fname in filenames:\n",
    "    orig_path = os.path.join(original_dir, fname)\n",
    "    recol_path = os.path.join(recolored_dir, fname)\n",
    "\n",
    "    if not os.path.exists(recol_path):\n",
    "        print(f\"Skipping missing: {recol_path}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        stsi, mean1, mean2 = process_image_pair(orig_path, recol_path, net)\n",
    "        stsi_values.append(stsi)\n",
    "        print(f\"{fname} → STSI: {stsi:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {fname}: {e}\")\n",
    "\n",
    "if stsi_values:\n",
    "    mean_stsi = np.mean(stsi_values)\n",
    "    print(f\"\\nMean STSI across {len(stsi_values)} images: {mean_stsi:.3f}\")\n",
    "else:\n",
    "    print(\"⚠️ No valid image pairs processed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple-streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
